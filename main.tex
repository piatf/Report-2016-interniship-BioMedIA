\documentclass[10pt]{report}
\usepackage[utf8]{inputenc}
\usepackage[top=2cm, bottom=2cm, left=2cm, right=2cm]{geometry}
\usepackage[francais]{babel}
\usepackage{helvet}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{lmodern}
\usepackage{listings}
\usepackage{amsmath} 
\usepackage{wrapfig}
\usepackage[colorlinks=true, linkcolor=black, urlcolor=blue, breaklinks, pagebackref, citebordercolor={0 0 0}, filebordercolor={0 0 0}, linkbordercolor={0 0 0}, pagebordercolor={0 0 0}, runbordercolor={0 0 0}, urlbordercolor={0 0 0}, pdfborder={0 0 0}]{hyperref}  %désactive les cadres autour des liens
\usepackage{etoolbox}
\renewcommand{\familydefault}{\sfdefault}

% Supprime l'espace avant l'en-tête des chapitres
\makeatletter
% les chapitres normaux
\patchcmd{\@makechapterhead}{\vspace*{50\p@}}{}{}{}	
% les chapitres étoilés
\patchcmd{\@makeschapterhead}{\vspace*{50\p@}}{}{}{}
\makeatother


\begin{document}

\begin{titlepage}	
	\flushleft
	\begin{figure}[!h]
		\includegraphics[height=1.8cm]{Reports/figures/logo_insa_cvl.png}
		\hfill
		\includegraphics[height=3cm]{Reports/figures/logo_biomedia.png}
	\end{figure}
	\centering
	\vspace{2cm}
	{\scshape\Large Stage industriel de 4ème année\par}
	\vspace{1.5cm}
	{\huge\bfseries Développement d'une bibliothèque mathématique performante pour le traitement d'images médicales\par}
	\vspace{2cm}
	{\Large\itshape Élève ingénieur: François PIAT\par}
		\vspace{1cm}
	\begin{figure}[!h]
		\begin{center}
			\includegraphics[width=13cm]{Reports/figures/biomedia_image.png}
		\end{center}
	\end{figure}
	\vfill
	\flushleft
	Tuteur INSA: \hfill Tuteurs BioMedIA: \par
	Dr. Julien \textsc{Olivier} \hfill Dr. Ghislain-Anthony \textsc{Vaillant} \\ \hfill Dr. Jonathan \textsc{Passerat-Palmbach}
	\vfill
	% Bottom of the page
	\centering
	{\large Année universitaire 2015 - 2016 \par}
\end{titlepage}

\section*{Remerciements}\newpage
\paragraph*{Résumé} % dans cet ordre
\paragraph*{Mots-clés}
\paragraph*{Abstract}
\paragraph*{Key-words}

\renewcommand\contentsname{Sommaire}
\tableofcontents

\newpage

\chapter*{Introduction}
\addcontentsline{toc}{chapter}{Introduction}

\chapter{Environnement de travail} 
	Cette section détaille l'environnement dans lequel s'est déroulé le stage. Suite à al présentation du laboratoire interviendra le cadre du projet.
	\section{Le laboratoire}
	
	\subsection{Imperial College London}~\par ~\par %souligner la section ou l'on est
	L’Imperial College London (officiellement The Imperial College of Science, Technology and Medicine) est une université britannique fondée en 1907 par la fusion du City and Guilds College, de la Royal School of Mines et du Royal College of Science (tous fondés entre 1845 et 1878).\\ ~\par
    L'université possède 9 campus au total, tous situés à Londres, et dont la plupart sont implantés dans des sites hospitaliers.  
    Elle possède 5 départements administratifs et 4 branches techniques: ingénierie, sciences naturelles, business, et médecine.	Le campus principal est localisé dans le quartier du South Kensington, et regroupe la branche d'ingénierie, de sciences naturelles, d'arts et de business. C'est sur ce campus que le département d'informatique se situe. 
    
	\begin{figure}[h!]
		\begin{center}
			\includegraphics[width=18cm]{Reports/figures/College-Organisation.pdf}
		\end{center}
		\caption{Organigramme de l'Imperial College London \\ \textit{Le département d'informatique, encadré en noir, se situe dans la branche d'ingénierie (en rouge) de l'université.}}
		\label{Organigramme de l'Imperial College London}
	\end{figure}
	
	\subsection{Department of computing}~\par~\par
	
	Le département d'informatique est divisé en 5 groupes de recherche : 
	\\{$\bullet$}\textit{\textbf{Logic and Artificial Intelligence:}} la recherche en Intelligence Artificielle et Logique englobe des études fondamentales de logique et une variété de disciplines en intelligence artificielle.
	\\{$\bullet$}\textit{\textbf{Distributed Software Engineering:}} la recherche dans le domaine de l'Ingénierie des Logiciels Distribués aborde la conception de systèmes distribués, adaptatifs et fiables.
	\\{$\bullet$}\textit{\textbf{Quantitative Analysis and Decision Science:}} la recherche en Analyse Quantitative et Science de la décision varie de l'optimisation à l'ingénierie de performances, en passant par la des expériences de vérifications quantitatives ou de sécurité.
	\\{$\bullet$}\textit{\textbf{Programming Languages and Systems:}} Systèmes et Langages de Programmation est une section qui combine des travaux théoriques et pratiques en langages et architecture pour obtenir des logiciels rapides, et efficaces.
	\\{$\bullet$}\textit{\textbf{Visual Information Processing:}} la recherche en Traitement d'informations Visualisables couvre une multitude de domaines, incluant la vision numérique, les graphiques, l'apprentissage automatique, et le traitement d'images médicales.
	 
	\begin{wrapfigure}[13]{r}{10cm}
		\includegraphics[width=9cm]{Reports/figures/research_strategy.jpg}
		\caption{Stratégie du département de recherche}
		\label{Stratégie du département de recherche}
	\end{wrapfigure}~\par~\par
	
	Les différentes spécialités citées précédemment sont articulées au sein du centre de recherche afin d'appliquer les résultats à d'autres domaines de recherche. Ces principales applications concernent les domaines de la santé, de la fiabilité/sécurité, de l'environnement, des modes de vie, de l'énergie et des incertitudes.
	\\
	\\
	\subsection{Le laboratoire BioMedIA}

	La mission du groupe BioMedIA est de développer de nouvelles techniques de
	calcul pour l'analyse d'images biomédicales. Le groupe se concentre sur des
	domaines de recherche de pointe, y compris:\\
	{$\bullet$} Le développement d'algorithmes d'acquisition, d'analyse et d'interprétation des images. En particulier dans les domaines du recalage, de la reconstruction,
	du suivi de mouvement, de la segmentation et de la modélisation. \\
	{$\bullet$} L'apprentissage machine pour l'extraction d'information clinique à partir
	d'images médicales. Les applications incluent le diagnostic assisté par
	ordinateur, la planification automatisée de traitement médical, ou encore la thérapie et les interventions guidées par ordinateur. \\
	Le laboratoire s'intéresse particulièrement à l'imagerie et les technologies de
	traitement informatique qui permet de mieux comprendre le
	développement du cerveau humain, l’évolution des maladies mentales et le
	diagnostic des patients atteints de maladie cardiovasculaire.
	
	\section{Cadre du projet} 
	\subsection{Medical Image Registration Toolkit (MIRTK)}~\par
	Le Medical Image Registration Tool-Kit (abrégé MIRTK) est un logiciel open-source de traitement d'images médicales codé en C++ et utilisé par des chercheurs dans le milieu médical. Le MIRTK prend en charge les formats d'image NIFTI, VTK et PNG. Il propose différents modules qui sont spécialisés pour le recalage d'images. \\ 
	L'utilisation du MIRTK se concentre autour d'une interface en lignes de commandes, incluant le nom de la fonction, les paramètres et les arguments nécessaires, et propres à chacune des fonctions. Par exemple, la ligne de commande suivante permet de rogner une image :
	
	\begin{lstlisting}
mirtk extract-image-region input.nii.gz output.nii.gz -Rx1 50 -Rx2 40 -Ry1 250 -Ry2 250
	\end{lstlisting}
	
	Sur cette ligne de commande:
	\\{$\bullet$} "mirtk" indique que la commande à exécuter est une commande du MIRTK.
	\\{$\bullet$} "extract-image-region" est la commande désirée. Celle-ci effectue un rognage.
	\\{$\bullet$} "input.nii.gz" indique l'emplacement de l'image d'entrée, idem pour la sortie avec "output.nii.gz". Ces fichiers sont au format NIFTI (ici compressées).
	\\{$\bullet$} "-R{$\lbrace$}x,y,z,t{$\rbrace$}{$\lbrace$}1,2{$\rbrace$}" permet de spécifier la région sur laquelle le rognage est effectué. 
	L'action de cette ligne de commande est visualisable sur la Figure \ref{Effet de la fonction "extract-image-region"}.
	
	\begin{figure}[h!]
		\centering
		\begin{subfigure}{.5\textwidth}
			\centering
			\includegraphics[width=5cm]{Reports/figures/mirtkextractregion1d.png}
			\caption{Image d'entrée}
			\label{Image d'entrée}
		\end{subfigure}%
		\begin{subfigure}{.5\textwidth}
			\centering
			\includegraphics[width=7cm]{Reports/figures/mirtkextractregion2_1d.png}
			\caption{Image de sortie}
			\label{Image de sortie}
		\end{subfigure}
		\caption{Effet de la fonction "extract-image-region"}.
		\label{Effet de la fonction "extract-image-region"}
	\end{figure}~\par
	
	Le dossier \textit{Applications} du MIRTK regroupe les fichiers correspondants aux commandes exécutables. Ils font appel à certaines dépendances, qui sont réparties en 7 modules : \textit{Common, Image, I/O, Numerics, PointSet, Registration} et \textit{Transformation}. 
	 Le recalage d'image (Registration) est l'une de ses principales fonctions.
	
	 \subsection{UK BioBank}~\par

	 \textit{UK BioBank} est une banque de données médicales du Royaume-Uni, et une association  ayant pour but d'améliorer la prévention, le diagnostic et le traitement d'un large éventail de maladies graves, y compris le cancer, les maladies cardiaques, les accidents vasculaires cérébraux, le diabète, l'arthrite, l'ostéoporose, les affections oculaires, la dépression et les formes de démence. 500.000 personnes âgées de 40 à 69 ans ont été recrutées sur la période 2006-2010 à l'échelle nationale pour prendre part à ce projet. Ils ont accepté de donner leur sang, leur urine et des échantillons de salive pour une analyse future, ainsi que des informations détaillées sur eux-mêmes et sur leur santé. D'ici plusieurs années, ce processus va aboutir sur une ressource majeure pour aider les scientifiques à découvrir pourquoi certaines personnes développent des maladies particulières, contrairement à d'autres.~\par~\par
	 
	 
	 
\chapter{Objectifs et cahier des charges}
	Lors de cette partie seront détaillées la motivation du stage, le cahier des charges et la planification des différentes étapes du projet.
	\section{Problématique} 
	Jusqu'ici, le MIRTK a été utilisé pour des études plus modestes, de l'ordre de la dizaine ou la centaine de patients. Pour cet ordre de grandeur, les performances actuelles du MIRTK sont suffisantes. Cependant avec UK BioBank, cette ordre de grandeur va augmenter significativement et le moindre gain de performance, à l'echelle du MIRTK, impactera le temps d'exécution globale sur la base de données UK BioBank.\\ ~\par
	
	Pour traiter un grand nombre de données, il est possible d'envoyer les calculs du MIRTK sur différents environnement d'exécution: %citer nombres pour faire tourner la tête, montrer qu'il y a des grosses possibilités
	\\{$\bullet$}\textbf{ sur une machine en local}, %pas un reseau, une machine 
	qui distribuera les tâches sur différents cœurs d'exécution. Les meilleurs processeurs à l'heure actuelle possède quelques dizaines cœurs.  
	\\{$\bullet$}\textbf{ une solution d'ordonnancement de tâches informatiques}, tel que SLURM, qui permet de créer des grappes de serveurs sous Linux ayant une tolérance aux pannes, de type ip-failover. Cette solution peut être utilisée sur des grappes de tailles variées, de deux à plusieurs milliers de serveurs.
	\\{$\bullet$}\textbf{ une grille de calculs}, plusieurs grilles étant disponibles, à des échelles différentes : \\%ex: euro(cern) / hpc (cf imperial)
	\t - La grille de l'Imperial College, qui s'étend à tout le réseau de machines de l'université, mais qui est un service payant. Cette grille met au total 5300 cœurs d'exécution à disposition.\\
	\t - La grille européenne, financée par l'Union Européenne et conduite par le CERN, qui met à disposition des services informatiques organismes européens de recherche. Ces services comprennent des environnements d'exécutions et plus de 500 PétaBytes de stockage de données (1 Pétabyte = 10\up{15} bytes). Concernant les environnements d'exécution, la grille fournit au total plus de 650 000 cœurs.
	\\{$\bullet$}\textbf{ sur un "nuage"}, c'est-à-dire un serveur que l'on loue à une entreprise qui propose un tel service, telles que Google ou Amazon.\\ ~\par
	Cependant, ces différents services possèdent chacun certaines contraintes. L'exécution sur un réseau local, une grille de calculs fournie par l'université ou un nuage serait payant, avec un prix croissant selon le temps d'exécution. Semblablement, un slurm ou une grille de calculs à l'échelle européenne utilisent les performances d'autres machines, qui, elles-même peuvent éventuellement être déjà occupées par l'exécution d'un autre logiciel. Si le temps d'exécution du MIRTK était réduit, cela représenterait un coût moindre dans un cas, un impact plus faible sur les ressources mutualisées dans l'autre.\\ ~\par
	Par conséquent, plusieurs directions sont possibles pour optimiser la durée de ces réquisitions. L'optimisation pourra intervenir au niveau de l'enchaînement des commandes sur un réseau de différentes machines: c'est sur cet aspect qu'a travaillé Mr. Maxime Noël, dans le cadre de son stage intitulé:"??????????????????".\\
	\vspace{-0.7cm}
	\newpage
	\begin{wrapfigure}[20]{r}{9cm}
		\includegraphics[width=10cm]{Reports/figures/gfor.eps}	
		\caption{Fonctionnement d'une boucle en parallèle}
		\label{Fonctionnement d'une boucle en parallèle}
	\end{wrapfigure}
	
	~\par~\par
	Une autre possibilité d'optimisation sera la réduction du temps d'exécution sur une machine. Pour cela, le MIRTK utilise une technique d'optimisation appelée "la parallélisation" d'un code. 
	A l'inverse de l'exécution séquentielle, la parallélisation est consiste à mettre en œuvre des architectures d'électronique numérique permettant de traiter des informations de manière simultanée, ainsi que les algorithmes spécialisés pour celles-ci. Ces techniques ont pour but de réaliser le plus grand nombre d'opérations en un temps le plus petit possible.
	Un algorithme adapté pour la parallélisation sépare l'exécution globale d'un programme en plusieurs "blocks" d'exécution, chacun correspondant à une sous-tâche. La figure \ref{Fonctionnement d'une boucle en parallèle} ci-contre représente ce principe avec des blocks de 2 itérations.\\

	Le MIRTK bénéficie seulement du multi-threading pour l'instant, et nécessite une amélioration sur le plan de ses performances sur plusieurs cœurs. De plus, bien que les opérations de traitement d'image utilisent souvent le GPU d'une machine, le MIRTK n'est pas capable d'utiliser ce genre d'accélérations matérielles.
	\\
	
	\section{Cahier des charges}
	La réduction du temps d'exécution est l'objectif principal du stage. Pour cela, l'amélioration sera envisagée sur les couches les plus bas niveau du MIRTK. Dans le cadre du stage, l'intervention se fera au niveau de l'utilisation des bibliothèques mathématiques, et de leur interaction avec les dépendances liées au hardware. Ces interactions sont gérées par des backends.\\ ~\par
	
	Un backend (parfois aussi appelé un arrière-plan) est un terme désignant un étage de sortie d'un logiciel devant produire un résultat. Plusieurs types de backends On l'oppose au front-end (aussi appelé un frontal) qui lui est la partie visible de l'iceberg. Pour l'utilisation de GPU, plusieurs backends sont disponibles: \\
	\t- \textit{CUDA ((Compute Unified Device Architecture)}, qui est compatible pour les GPU de la marque Intel.
	\t- OpenCL (Open Computing Language), qui est un backend semblable à CUDA, mais compatible avec davantage de dispositifs hardware (y compris certains CPU), puisqu'il est open-source.\\
	
	Dans le cadre du stage, les 3 axes de développement ont été définis : \\
	\\{$\bullet$} Le support de l'exécution sur différents backends, que ce soit pour CPU ou GPU. A l'heure actuelle, la gestion des backends GPU n'est pas assurée par le logiciel. Dans l'idéal, le MIRTK gérerait automatiquement cet aspect, en vérifiant la présence d'une carte graphique sur l'ordinateur (sinon utiliser le CPU), puis le laisser choisir entre CPU et GPU pour des performances optimales. Si, par exemple, un ordinateur possède une bonne carte graphique, le MIRTK devra être apte à le détecter, puis l'utiliser.\\
	\\{$\bullet$} Garder l'intégrité et la transparence du code du MIRTK. Il sera imposé de garder la même interface, les mêmes ligne de commande. Pour conserver cela, il faudra garder une transparence entre le code du MIRTK et la gestion de différents backend. \\
	\\{$\bullet$} Dans la mesure du possible, un réusinage devra être opéré. Le réusinage de code (\textit{code refactoring}, en anglais) est l'opération consistant à retravailler le code source d'un programme informatique (sans toutefois y ajouter des fonctionnalités ni en corriger les bogues) de façon à en améliorer la lisibilité et par voie de conséquence la maintenance, ou à le rendre plus générique (afin par exemple de faciliter le passage de simple en multiple précision); on parle aussi de « remaniement ». Suite à la modification du code du MIRTK, ainsi qu'à l'ajout probable certaines fonctionnalités, il est possible que des doublons subsistent, et que la lisibilité de certaines parties du code peut s'améliorer.	
	\section{Planification}
	\subsection{Objectifs} 
	Afin de se familiariser avec le MIRTK, les objectifs ont été établis de manière chronologique, de la manière suivante: 
	~\par~\par 
	1) \textbf{Études du MIRTK et de ses dépendances, et analyse de l'interface d'ArrayFire} \\
	Cette étape préliminaire permettra de comprendre le fonctionnement global du MIRTK et de se familiariser avec son code source. Dans le même temps, l'analyse de l'interface d'ArrayFire, une bibliothèque mathématique optimisée, et des différentes fonctions proposées par la bibliothèque sera entreprise. Cette étude corrélera donc les besoins du MIRTK et les solutions proposées par ArrayFire.
	~\par~\par 
	2) \textbf{Profilage du MIRTK}\\
	Afin d'obtenir une première visualisation des performances du logiciel, un profilage sera exécuté sur les fonctions concernées. Il consistera à analyser l'exécution du MIRTK afin de connaître son comportement à l'exécution. L'interprétation de ces premiers résultats sera nécessaire pour élaborer un ordre de priorité dans les fonctions à ré-implémenter.
	~\par~\par 
	\t 3) \textbf{Intégration de ArrayFire dans le MIRTK} \\
	A la suite du profilage sera donc obtenue une liste de fonctions à implémenter primordialement. La modification de ces fonctions sera implémentée indépendamment, en commençant par les fonctions dont la ré-implémentation sera la plus simple, en progressant ensuite sur celles plus complexes.
	~\par~\par
	\t 4) \textbf{Implémentation de la gestion optimisée des backends} \\
	Comme détaillé dans la partie 2.2 précédente, la gestion des backends serait un avantage pour les performances du MIRTK. Pour cette raison, cette gestion sera idéalement implémentée en fin de stage. 
	~\par~\par 
	\t 5) \textbf{Analyse des performances} \\
	Pour prouver l'efficacité d'ArrayFire et l'amélioration des performances du MIRTK, un test des fonctions précédemment optimisées sera réalisé. Les résultats attendus sont principalement des graphiques reflétant cette amélioration.
%	Détailler les objectifs a atteindre idéalement.
%	- Ajouter ArrayFire à MIRTK, en remplaçant les fonctions d'EIGEN les moins adaptées par les fonctions d'AF. \newline
%	- Faire un profiling des fonctions concernées par TBB, et interpréter les résultats afin d'élaborer une stratégie pour implanter la programmation // d'AF.\newline
%	- Supprimer les TBB inutiles ou peu efficaces, et remplacer les autres par l'équivalent d'AF (gfor).\newline
%	\noindent Dans un premier temps, il faudrait analyser le code de MIRTK sur deux plans:\\~\par 
%	\t - Les fonctions utilisées par Eigen et qui seraient davantage adaptées avec ArrayFire \\~\par
%	\t - Les outils de parallélisation et l'utilisation de la bibliothèque TBB \\\\
%	La première étape se fera simplement en comparant l'utilisation directe de Eigen, ainsi que les interdépendances des fichiers MIRTK avec ceux de la bibliothèque. Cependant, la deuxième demandera une analyse plus approfondie: en plus d'une analyse de code tel que précédemment avec EIGEN, il faudra réaliser un "test de performance" sur certaines fonctions. Ce test est appelé un profilage (ou \textit{profiling} en anglais) et peut analyser différents critères. Ainsi pourrons-nous cibler les fonctions les plus urgentes à modifier, qui sont mal rédigées ou qui demande relativement trop de ressources.
%	A la suite de ce profilage sera donc élaboré un "plan d'attaque" pour savoir par quelle partie du projet commencer.
%	\t - A terme, après avoir retiré au maximum les dépendances de MIRTK avec TBB, on pourra commencer des tests de benchmarking afin de vérifier l'amélioration des performances.
	\subsection{Diagramme de GANTT}
%	 => gantt chart prévisionnel (à mettre en français)
%	\begin{figure}[h!]
%		\begin{center}
%			\includegraphics[width=18cm]{Reports/figures/estimated_gantt.png}
%		\end{center}	
%		\caption{Diagramme de GANTT prévisionnel}
%		\label{Diagramme de GANTT prévisionnel}
%	\end{figure}
\chapter{Réalisation du stage}
	\section{Introduction à ArrayFire}

	
	\section{Implémentation}
	\subsection{Intégration de ArrayFire dans le MIRTK} 
	%	Programmation transparente entre Eigen et ArrayFire.
	%	Lister les fonctions principales à substituer.
	
	% A refaire !!!!
%	L'une des premières fonctions qui nous a attiré était un filtre, qui avait une implémentation assez simple (un simple produit de convolution de deux matrices). On a donc choisi de s'y intéresser avec ArrayFire.
%	Ce filtre a été précédemment profilé, il s'agit de la fonction \textit{smooth-image}. La version de MIRTK était déjà implémentée de manière séparable, c'est-à-dire que le floutage est réalisé une dimension après l'autre, et c'est la méthode la plus optimisée pour un tel calcul. Cependant, on a tout de même remplacé l'implémentation existante en intégrant ArrayFire afin de comparer les performances et simplifier le code de la fonction. \\
%	Dans un premier temps, une implémentation naïve a été initiée en reprenant à zéro le code de la fonction. Le floutage d'une image se fais par un produit de convolution entre la matrice représentant l'image, et le filtre (gaussien), qui est déclaré dans la fonction elle-même. L'implémentation naïve a donc été de réaliser ce produit de convolution de matrices en utilisant la fonction \textit{af::convolve}, qui réalise simplement la convolution du filtre 3D avec l'image 3D, comme on peut le voir ci-dessous:\\
%	\begin{figure}[h!]
%		\begin{center}
%			\includegraphics[width=11cm]{Reports/figures/gaussianblurring.png}
%		\end{center}	
%		\caption{Algorithme de flou gaussien incluant Arrayfire - Implémentation naïve}
%		\label{Algorithme de flou gaussien incluant Arrayfire - Implémentation naïve}
%	\end{figure}~\par
%	Afin d'optimiser au maximum la fonction, il faut maintenant la ré-implémenter de la même manière que dans MIRTK, c'est-à-dire de manière séparable. Pour cela on effectue sur chaque dimension un produit de convolution sur la dimension 1 de la matrice, qu'on réordonne après, de telle manière à faire passer les valeurs de la dimension choisie en première dimension: \\
%	\begin{figure}[h!]
%		\begin{center}
%			\includegraphics[width=12cm]{Reports/figures/mygaussianblurring.png}
%		\end{center}	
%		\caption{Algorithme de flou gaussien incluant Arrayfire - Implémentation optimisée}
%		\label{Algorithme de flou gaussien incluant Arrayfire - Implémentation optimisée}
%	\end{figure}~\par
	\subsection{Dette technique}
	%	Optimisation des threads et suppression de TBB au profit de ArrayFire.
	
	
	
	
	%	\newline
	%	Le contenus des sous-parties, ainsi que d'éventuelles d'autres sous-parties dépendront du résultat du profilage.
	
	\section{Analyse des performances}
		\subsection{Profilage}
	%	Définir le profilage et expliquer la nécessité d'une telle étape dans ce contexte\newline
	
		% a refaire!!!
%		Lors du début de mon stage, il a fallu que je me familiarise avec les dépendances de MIRTK, mais aussi a son fonctionnement interne. C'est lors de cette étude préliminaire que mon tuteur et moi avons étudié, en plus de la bibliothèque EIGEN (destinée aux fonctionnalité mathématiques), la bibliothèque TBB, qui a pour but de mettre en place une parallélisation d'un logiciel. Constatant qu'ArrayFire était constitué de fonctions mathématiques déjà optimisées sur ce plan, il a été convenu de faire un profilage de MIRTK avant d'y intégrer ArrayFire afin de prioriser les points les plus coûteux en ressources de MIRTK. \\
%	%	Les tests ont été effectués sur une machine dont les caractéristiques sont les suivantes : \newline
%	%	{$\bullet$} \textit{Nombre de coeurs:} 8, 2 threads chacun\newline
%	%	{$\bullet$} \textit{Cadence:} 1.6 GHz \newline
%	%	{$\bullet$} \textit{Nombre de caches:} 4 \newline
%	%	{$\bullet$} \textit{Taille des caches:}32k, 32k, 256K, 8192K \newline
%		%ajouter le maximum de détails (RAM, nom du proc ...)\newline
%		Pour une quantité réduite de tests, et afin de cibler les modèles d'utilisation de TBB à remplacer, on a pris l'une des fonctions les plus sollicitées dans MIRTK, il s'agit d'une fonction nommée \textit{transform-image}, et qui dispose de 5 options, définissant un type d'interpolation mathématique : Linéaire (par défaut), méthode voisin le plus proche (NN), gaussienne, sinus cardinal et B-Spline. \\
%		On notera, de plus, que tous ces tests seront exécutés sur la même machine afin de garder des performances exactement semblables à chaque exécution.
%		
%		\subsection{Choix du profileur}~\par
%		Afin de discerner au mieux les performances de MIRTK, le choix du profileur (l'outil faisant le profilage) était important. Le principal poste utilisée pour le profilage travaille sur un processeur INTEL, ce qui nous a convaincu de ne pas utiliser le profileur CodeXl puisque nous avons compris après installation qu'il ne fonctionnait qu'avec des processeurs AMD. On a ensuite basculé sur VTune, développé par les collaborateurs directs d'AMD, mais nous ne l'avons pas retenu non plus de part sa complexité d'installation sur l'ordinateur souhaité.
%		
%		Nous avons donc finalement choisi d'utiliser l'outil Callgrind de la suite VALGRIND (qui est open-source), capable d'analyser à la fois la quantité d'instructions envoyées au run-time, et aussi les fuites de cache.
%		Ci-dessous est affichée l'interface utilisateur de Kcachegrind, qui est un outil permettant de visualiser de manière claire les résultats de Callgrind:
%		\begin{figure}[h!]
%			\begin{center}
%				\includegraphics[width=13cm]{Reports/figures/UIkcachegrind.png}
%			\end{center}	
%			\caption{Interface de KCacheGrind pour le profilage}
%			\label{Interface de KCacheGrind pour le profilage}
%		\end{figure}~\par
%		{$\bullet$} \textit{Cadre vert: } Dans cette partie est distinguée tous les threads qui ont exécuté une partie du code lié à l'exécutable étudié. Tous les threads ayant été utilisés dans ce cas, on peut constater que la machine fonctionne donc avec 4 coeurs. \newline
%		{$\bullet$} \textit{Cadre bleu: } Ici est détaillé toutes les fonctions les plus coûteuses du thread sélectionné. \newline
%		{$\bullet$} \textit{Cadre rouge: } Grâce à ce diagramme, on peut visualiser la pile d'appel des fonctions avant et après la fonction sélectionné dans le cadre bleu. Les onglets en bas de page sont d'autres représentations plus textuelles (et plus détaillées) de ce que montre le diagramme. \newline
%		
%		
%	
%	%	=> on identifie les fonctions sur lesquelles agir en premier
%	%	On utilise Valgrind, qui, avec callgrind analyse la manière dont les caches sont utilisés.
%	%	Expliquer le choix de valgrind, parmi les autres profileurs
%	% => projet open-source multi-plateforme et disponible dans les packages linux, autres alternatives étudiées (VTUNE intel, installation compliquée, et codeXL, qui nécessite des proc AMD).\\
%		
%		
%	
%		
%		\paragraph{Analyse du nombre d'instructions}
%		
%		\begin{wrapfigure}{r}{7.2cm}
%			\includegraphics[height=9cm]{Reports/figures/smooth_image_costs.eps}
%			\caption{Coût de la fonction de flou gaussien}
%			\label{Coût de la fonction de flou gaussien}
%		\end{wrapfigure}
%		~\par~\par
%		Dans un premier temps, on s'intéresse au critère le plus pertinent concernant les performances du logiciel. Le nombre d'instructions correspond à la quantité de commandes atomiques (au niveau binaire) exécutées par le CPU et pour chaque thread.
%		Ainsi, on peut étudier l'efficacité de TBB en comparant le nombre d'instructions utilisées lorsque TBB est activé ou non. C'est ce qui est présenté sur l'image présentée ci-contre, en se focalisant sur une fonction de flou gaussien (nommée \textit{smooth-image}).\\
%		Sur l'axe des ordonnées, on a le coût total en instruction de la fonction, appelée sur une machine précise, avec une entrée précise (ici une image 3D). Les résultats dépendent de ces deux critères.Cependant, le ratio entre les coûts de la fonction parallélisée et celle qui ne l'est pas reste sensiblement le même. Au bas de l'image, on peut voir qu'ici, la fonction à un taux d'amélioration de x1.59. L'ordinateur ayant exécuté cette fonction ayant 8 coeurs, on peut dire que ce résultat reflète une mauvaise parallélisation dans ce cas, car un logiciel bien optimisé aurait un taux d'amélioration proche de x8 (équivalent au nombre de coeurs utilisés).\\
%		De même, ci-dessous, l'image décrit les performances de la fonction \textit{transform-image}. En revanche, ici, cette fonction possède une option qui permet de choisir son type d'interpolation mathématique. On a donc fait un test de coût d'instructions pour chaque interpolation et on a relevé ici le taux de performance associé:
%		\begin{figure}[h!]
%			\begin{center}
%				\includegraphics[width=9cm]{Reports/figures/performances_tbb_transform_image.eps}
%			\end{center}	
%			\caption{Améliorations apportées par TBB pour transform-image}
%			\label{Améliorations apportées par TBB pour transform-image}
%		\end{figure}~\par
%		L'interpolation gaussienne est donc parfaitement parallélisée, ce qui n'est pas le cas des autres interpolations de \textit{transform-image}.
%		
%		\paragraph{Analyse des fuites de cache}
%		Un deuxième critère intéressant à regarder, au travers du profilage, est la quantité de fuites de caches à l'exécution de la fonction étudiée. Bien que la parallélisation ne soit pas toujours optimale, elle peut néanmoins être parfois délaissée au profit d'une gestion de fuites de caches plus poussée.
%		
%		\subparagraph{Qu'est-ce qu'une fuite de cache?}
%		\textit{?????}\\
%		Ci-dessous est détaillé l'histogramme de la quantité des fuites de caches pour \textit{transform-image}, dans chaque mode d'interpolation:
%			\begin{figure}[h!]
%				\begin{center}
%					\includegraphics[width=15cm]{Reports/figures/cache_misses_transform_image.eps}
%				\end{center}	
%				\caption{Fuites de cache pour la fonction transform-image}
%				\label{Fuites de cache pour la fonction transform-image}
%			\end{figure}~\par
%		Les valeurs données ci-dessus (en pourcentage) sont assez mal réparties, mais le faible "cache miss rate" (taux de fuites de caches) est très faible. Le seul taux non négligeable est celui des mauvaises prédictions de branche, qui peut être considéré comme une fuite de cache, mais un taux inférieur à 20 \% reste négligeable. 
%		~\par
%		MIRTK est donc bien conçu au niveau de la gestion de la mémoire cache, alors que le système de parallélisation est largement améliorable.

%	\subsection{Switch automatique de back-end}
%	Commandes prépocesseur pour indiquer au logiciel quel est le back-end à utiliser (ArrayFire ou Eigen) en fonction de l'opération souhaitée.

	\subsection{Parangonnage}
%	(partie dépendante du déroulement du projet)\newline
%	- Analyse des performances obtenues \newline
%	- Comparaison avec le profilage initial ? \newline
%	- Points où il y a eu des concessions (exemple: alourdir le code pour parvenir à un résultat précis)
	
\chapter{Améliorations et perspectives}
	\section{A cours terme}
	\section{A long terme}

\chapter*{Conclusion} % dans cet ordre
\addcontentsline{toc}{chapter}{Conclusion}
\chapter*{Sources}
\addcontentsline{toc}{chapter}{Sources}
\noindent
\url{https://biomedia.doc.ic.ac.uk/}  : image page de garde, partie du texte 1.1.3 \\
\url{http://www.imperial.ac.uk} : partie du texte 1.1.2 (Department of computing) et schéma stratégie du département\\
\url{https://fr.wikipedia.org/wiki/Imperial_College_London} : partie du texte 1.1.1 (Imperial College London)\\
\url{http://www.ukbiobank.ac.uk/about-biobank-uk/} : inspiration pour le paragraphe 1.2.2 (UK BioBank)\\
\url{http://ric.uthscsa.edu/mango/papaya/index.html} : outil de visualisation d'images en format NIFTI\\
\url{https://wiki.imperial.ac.uk/display/HPC/Systems} : données sur la grille de calcul de l'Imperial College\\
\url{http://www.egi.eu/} : données sur la grille européenne de calcul
\url{https://fr.wikipedia.org/wiki/SLURM} : définition du SLURM, partie 2.1\\
\url{https://fr.wikipedia.org/wiki/Parall\%C3\%A9lisme_\%28informatique\%29} : définition de la parallélisation, partie 2.1\\
\url{https://fr.wikipedia.org/wiki/Backend} : définition d'un backend\\
\url{https://fr.wikipedia.org/wiki/R\%C3\%A9usinage_de_code} :  définition d'un réusinage \\
\renewcommand{\listfigurename}{Table des illustations}
\listoffigures
\addcontentsline{toc}{chapter}{Table des illustrations}
\chapter*{Glossaire}
\addcontentsline{toc}{chapter}{Glossaire}
\noindent
\textbf{Back-end:}\\ 
\textbf{Front-end:}\\
\textbf{Profilage:} Différence avec le benchmarking ?\\
\textbf{Run-time:}\\
\textbf{Fuite de cache:}\\
\textbf{Parangonnage:} Différence avec le profiling ?\\
\textbf{Thread:}\\
\textbf{Prédiction de branche:}\\
\textbf{Fuite de cache:}\\
\textbf{Environnement d'exécution:}\\
\textbf{CPU:}\\
\textbf{GPU:}\\

\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{mymauve}{rgb}{0.58,0,0.82}

\lstset{ %
	backgroundcolor=\color{white},   % choose the background color
	basicstyle=\footnotesize,        % size of fonts used for the code
	breaklines=true,                 % automatic line breaking only at whitespace
	captionpos=b,                    % sets the caption-position to bottom
	commentstyle=\color{mygreen},    % comment style
	escapeinside={\%*}{*)},          % if you want to add LaTeX within your code
	keywordstyle=\color{blue},       % keyword style
	stringstyle=\color{mymauve},     % string literal style
}

\begin{appendix}
	\chapter*{Annexe 1: Implémentation de "smooth-image" en Python}
	\addcontentsline{toc}{chapter}{Annexe 1: Implémentation de "smooth-image" en Python}
	\begin{lstlisting}[language=python]
import arrayfire as af
from array import array
import matplotlib.pyplot as plt
import nibabel as nib 
from scipy import signal
from scipy.fftpack import fft, fftshift 
import numpy as np
import argparse as ap

if __name__ == '__main__':
	
	# Command line arguments and options handling 
	parser = ap.ArgumentParser()
	parser.add_argument("InputImage", type=str, help="Path to the input image")
	parser.add_argument("OutputImage", type=str, help="Path to the input image")
	parser.add_argument("Sigma", type=int, help="Defines the value of sigma for the Gaussian kernel. Default: 1")
	parser.add_argument("--dimension", type=str, choices=["x", "y", "z", "xy", "yz", "xz", "xyz"], help="Specifies on which dimensions execute the blurring. Default: xyz")
	parser.add_argument("-color", help="Enable colored input/output image plot.", action="store_false")
	parser.add_argument("-nodisplay", help="Cancel plot of the input/output images. Has priority over \"-color argument\".", action="store_false")
	
	args = parser.parse_args()
	
	# Loading input
	img = nib.load(args.InputImage)
	hdr = img.get_header()
	img_data = img.get_data().astype('f')
	
	# Conversion numpy => arrayfire
	img_data_af = af.interop.np_to_af_array(img_data)
	
	# Declaration of Gaussian kernel
	if args.Sigma:
		kernel = signal.gaussian(img_data.shape[0], std = args.Sigma).astype('f')
	else:
		kernel = signal.gaussian(img_data.shape[0], std = 1).astype('f')
	
	# Conversion numpy => arrayfire for the Gaussian kernel
	kernel_af = af.interop.np_to_af_array(kernel)
	
	# Convolution along dimensions chosen 
	output_image = img_data_af.copy()
	input_image = img_data_af.copy()
	
	if (args.dimension):
	
		if ("x" in args.dimension):
			output = af.convolve1(input_image, kernel_af)
		
		if ("y" in args.dimension):
			input_image = af.reorder(output_image, 1, 0, 2)
			output_image = af.convolve1(input_image, kernel_af)
			output_image = af.reorder(output_image, 1, 0, 2)
		
		if ("z" in args.dimension):
			input_image = af.reorder(output_image, 2, 1, 0)
			output_image = af.convolve1(input_image, kernel_af)
			output_image = af.reorder(output_image, 2, 1, 0)
	else:
		output_image = af.convolve1(input_image, kernel_af)
		input_image = af.reorder(output_image, 1, 0, 2)
		output_image = af.convolve1(input_image, kernel_af)
		output_image = af.reorder(output_image, 1, 0, 2)
		input_image = af.reorder(output_image, 2, 1, 0)
		output_image = af.convolve1(input_image, kernel_af)
		output_image = af.reorder(output_image, 2, 1, 0)
	
	
	# Conversion arrayfire => numpy
	output_np = output_image.to_array()
	output_np = np.asarray(output_np)
	output_np = output_np.reshape(320, 250, 202, order='F')
	
	# Saving the output file
	affine = img.get_affine()
	new_img = nib.Nifti1Image(output_np, affine)
	nib.save(new_img, args.OutputImage)
	
	# Check if plot is not cancelled by "-nosdisplay" argument
	if (args.nodisplay == True):
		# Assimilating color option
		if (args.color):
		colors = 'gray'
		else:
		colors = None
		
		# Ploting 1rst window
		f,fig = plt.subplots(1, 2)
		fig[0].imshow(img_data[125, :, :].T, extent=[0, hdr['pixdim'][1], 0, hdr['pixdim'][3]], cmap=colors, origin='lower')
		fig[1].imshow(output_np[125, :, :].T, extent=[0, hdr['pixdim'][1], 0, hdr['pixdim'][3]], cmap=colors, origin='lower')
		plt.suptitle("Gaussian Blurring on x-axis")
		
		# Ploting 2nd window
		f2,fig2 = plt.subplots(1, 2)
		fig2[0].imshow(img_data[:, 125, :].T, extent=[0, hdr['pixdim'][1], 0, hdr['pixdim'][3]], cmap=colors, origin='lower')
		fig2[1].imshow(output_np[:, 125, :].T, extent=[0, hdr['pixdim'][1], 0, hdr['pixdim'][3]], cmap=colors, origin='lower')
		plt.suptitle("Gaussian Blurring on y-axis")
		
		# Ploting 3rd window
		f3,fig3 = plt.subplots(1, 2)
		fig3[0].imshow(img_data[:, :, 125].T, cmap=colors, origin='lower')
		fig3[1].imshow(output_np[:, :, 125].T, cmap=colors, origin='lower')
		plt.suptitle("Gaussian Blurring on z-axis")
		
		plt.show()
	\end{lstlisting}
\end{appendix}

\end{document}
