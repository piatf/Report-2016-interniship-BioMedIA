\documentclass[10pt]{report}
\usepackage[utf8]{inputenc}
\usepackage[top=2cm, bottom=2cm, left=2cm, right=2cm]{geometry}
\usepackage[francais]{babel}
\usepackage{helvet}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{lmodern}
\usepackage{wrapfig}
\usepackage[colorlinks=true, linkcolor=black, urlcolor=blue, breaklinks, pagebackref, citebordercolor={0 0 0}, filebordercolor={0 0 0}, linkbordercolor={0 0 0}, pagebordercolor={0 0 0}, runbordercolor={0 0 0}, urlbordercolor={0 0 0}, pdfborder={0 0 0}]{hyperref}  %désactive les cadres autour des liens
\usepackage{etoolbox}
\renewcommand{\familydefault}{\sfdefault}

% Supprime l'espace avant l'en-tête des chapitres
	\makeatletter
	% les chapitres normaux
	\patchcmd{\@makechapterhead}{\vspace*{50\p@}}{}{}{}	
	% les chapitres étoilés
	\patchcmd{\@makeschapterhead}{\vspace*{50\p@}}{}{}{}
	\makeatother


\begin{document}

\begin{titlepage}	
	\flushleft
	\begin{figure}[!h]
		\includegraphics[height=1.8cm]{Reports/figures/logo_insa_cvl.png}
		\hfill
		\includegraphics[height=3cm]{Reports/figures/logo_biomedia.png}
	\end{figure}
	\centering
	\vspace{2cm}
	{\scshape\Large Stage industriel de 4ème année\par}
	\vspace{1.5cm}
	{\huge\bfseries Développement d'une bibliothèque mathématique performante pour le traitement d'images médicales\par}
	\vspace{2cm}
	{\Large\itshape Élève ingénieur: François PIAT\par}
		\vspace{1cm}
	\begin{figure}[!h]
		\begin{center}
			\includegraphics[width=13cm]{Reports/figures/biomedia_image.png}
		\end{center}
	\end{figure}
	\vfill
	\flushleft
	Tuteur INSA: \hfill Tuteur BioMedIA: \par
	Julien \textsc{Olivier} \hfill Ghislain-Anthony \textsc{Vaillant}
	\vfill
	% Bottom of the page
	\centering
	{\large Année universitaire 2015 - 2016 \par}
\end{titlepage}

\section*{Remerciements}\newpage
\paragraph*{Résumé} % dans cet ordre
\paragraph*{Mots-clés}
\paragraph*{Abstract}
\paragraph*{Key-words}

% sommaire
\renewcommand\contentsname{Sommaire}
\tableofcontents

\newpage

\chapter*{Introduction}
\addcontentsline{toc}{chapter}{Introduction}
\chapter{Environnement de travail} 
	\section{Le laboratoire}
		Le laboratoire BioMedIA est implanté sur le campus principal de l'Imperial College London, dans le quartier du South Kensington. Il fait partie du groupe de recherche en traitement visuel d'informations (Visual Information Processing) au sein du département informatique de l'université.
	\subsection{Imperial College London - Department of computing}
%	Domaine d'activité, stats, organigramme

	
	%	Visual Information Processing research covers a range of topics including vision, graphics, intelligent behaviour understanding, and biomedical image computing.
	%	
	%	The work of the section has led to more than 8 best paper awards at major international conferences (IEEE FG, ICRA, ISMAR, MICCAI, SensorComm) and attracted four Marie Curie fellows.
	%	
	%	The group has pursued a successful strategy of growth in several key areas:  novel modelling and filtering approaches for SLAM and real-time dense scene mapping.
	%	
	%	Intelligent behavior understanding, novel approaches to facial action and emotion prediction as well as novel approaches to robust face alignment, tracking and expression recognition, biomedical imaging computing, robotics & sensing, and appearance modelling for realistic computer graphics.
	\paragraph{Imperial College London}~\par
		\begin{figure}[h!]
			\begin{center}
				\includegraphics[width=18cm]{Reports/figures/College-Organisation.pdf}
			\end{center}	
			\caption{Organigramme de l'Imperial College London}
			\label{Organigramme de l'Imperial College London}
		\end{figure}
	L’Imperial College London (officiellement The Imperial College of Science, Technology and Medicine) est une université britannique, se situant à Londres dans le quartier de South Kensington. Elle est spécialisée dans les sciences, l'ingénierie, la médecine et les études commerciales (avec Imperial College Business School). L'Imperial College attire des étudiants du monde entier (plus de 125 nationalités représentées en 2016).
	
	Fondée en 1907, l'Imperial College était d'abord une des composantes de l’université de Londres, avant de devenir une institution indépendante à l'occasion de son centenaire, en 2007. Elle est membre de la Ligue européenne des universités de recherche depuis le 1er janvier 2010. L'Imperial est également membre du Russell Group, du G5, de l'Association des Universités du Commonwealth et du "Golden Triangle" des universités britanniques.
	
	\paragraph{Department of computing}~\par~\par
	Le département d'informatique est divisé en 6 groupe de recherche : \textit{Logic and Artificial Intelligence, Distributed Software Engineering, Quantitative Analysis and Decision Science, Programming Languages and Systems, Intersection Research}, et celui de notre laboratoire : \textit{Visual Information Processing}.\\ 
	La stratégie menée par le centre de recherche est la suivante : 
	\begin{figure}[h!]
		\begin{center}
			\includegraphics[width=10cm]{Reports/figures/research_strategy.jpg}
		\end{center}	
		\caption{Stratégie du département de recherche}
		\label{Stratégie du département de recherche}
	\end{figure}~\par 
		
	La recherche en traitement visuel d'informations intervient dans de nombreux domaines tels que la visualisation, le graphisme, la compréhension intelligente, et le traitement d'images biomédicales.  
	Les travaux du département ont été récompensés de 8 titres lors de conférences internationales majeures (IEEE FG, ICRA, ISMAR, MICCAI, SensorComm) et de 4 prix Marie Curie.
	blue

	
	\subsection{BioMedIA}
%	Synopsis, détail des activités du laboratoire
	
	La mission du groupe BioMedIA est de développer de nouvelles techniques de
	calcul pour l'analyse d'images biomédicales. Le groupe se concentre sur des
	domaines de recherche de pointe, y compris:\\

	{$\bullet$} Le développement d'algorithmes d'acquisition, d'analyse et d'interprétation des images. En particulier dans les domaines du recalage, de la reconstruction,
	du suivi de mouvement, de la segmentation et de la modélisation. \\

	{$\bullet$} L'apprentissage machine pour l'extraction d'information clinique à partir
	d'images médicales. Les applications incluent le diagnostic assisté par
	ordinateur, la planification automatisée de traitement médicale, ou encore les
	interventions et la thérapie guidées par ordinateur. \\

	Nous nous intéressons particulièrement à l'imagerie et les technologies de
	traitement informatique qui nous permettent de mieux comprendre le
	développement du cerveau humain, l’évolution des maladies mentales et le
	diagnostic des patients atteints de maladie cardiovasculaire.
	
	
	\section{Cadre du projet} % présentation de MIRTK, de ses applications, de son architecture(modules, fonctions...).
	\paragraph{Medical Image Registration Toolkit (MIRTK)}~\par~\par
	Medical Image Registration Tool-Kit (abrégé MIRTK) est un logiciel open-source de traitement d'image médicales utilisé par des chercheurs dans le milieu médical. Le cahier des charges provient majoritairement de ces chercheurs, qui ont des besoins variables en termes de visualisation. Le logiciel est adapté en conséquence par la suite. Par conséquent, MIRTK, qui est codé en C++, comporte un nombre important de classes et de fonctions diverses, destinées à couvrir le maximum des besoins des chercheurs.
	Afin de rester pertinent pour ces chercheurs, MIRTK nécessite donc une maintenance et une amélioration continue.\\
	Pour illustrer le fonctionnement du logiciel, on peut étudier l'action d'une fonction en particulier. Prenons la fonction "extract-image-region", qui correspond à un rognage d'image, en 3 dimensions.

	\begin{figure}[h!]
		\begin{center}
			\includegraphics[width=10cm]{Reports/figures/mirtkextractregion1.png}
		\end{center}	
		\caption{Image fournie en entrée de "extract-image-region"}
		\label{Image fournie en entrée de "extract-image-region"}
	\end{figure}~\par
	
	Comme vous pouvez le constater ci-dessus, l'image en entrée du logiciel est une image en 3 dimensions. C'est d'ailleurs ce qui fait la force de MIRTK: il peut agir sur des images en 2, 3, ou 4 dimensions (la quatrième dimension représentant le temps). L'image est ici en noir et blanc, mais des travaux de segmentations notamment, peuvent aussi bien utiliser des palettes de couleurs. Le cadre rouge est purement fictif et indique simplement les limites du rognage effectué.
	
	\begin{figure}[h!]
		\begin{center}
			\includegraphics[width=10cm]{Reports/figures/mirtkextractregion2.png}
		\end{center}	
		\caption{Image obtenue après rognage 3D}
		\label{Image obtenue après rognage 3D}
	\end{figure}~\par 
	
	Ci-dessus est maintenant présentée l'image de sortie, les paramètres de la fonction "extract-image-region" ayant été passés en ligne de commande. Il suffit d'indiquer les limites désirées sur chaque axe pour obtenir un tel résultat.\\
	\\
	On notera que cet exemple est très loin de refléter l'ensemble des capacités du logiciel. En effet, MIRTK agit aussi bien sur des filtres d'images, que de transformations, de recalages, de conversions... 
	 % - logiciel de traitement d'image médicales, utilisé par les chercheurs en milieu médical.
	 % - stable mais nécessite une maintenance et une amélioration continue pour rester pertinent.
	 % - Intervention sur le module "Numerics", bibliothèque mathématique.
	 \paragraph{UK BioBank}~\par~\par
	  A long terme, MIRTK serait potentiellement destiné a faire partie d'un projet global pour la UK BioBank qui prévoit de regrouper la plus grosse banque de données médicales, incluant notamment des données visualisables. Cette base de données regroupera aussi des dizaines de caractéristiques pour chaque patient (habitude alimentaires, antécédents médicaux, génotype...). Afin de pouvoir traiter un tel nombre de données, MIRTK n'est pas suffisamment optimisé. Le but principal de ce stage est donc de commencer la démarche d'amélioration du logiciel en terme de design et de performances.
	 

\chapter{Objectifs et cahiers des charges}
	\section{Problématique} %Inclure contexte du projet, avec la raison pour laquelle ce projet est nécessaire.
	%(back-end math) dépendances externes : eigen et boost + noyaux internes implémentés via TBB => inconsistence => parrallélisation existante floue , efficacité = ? performances=? => profilage	===> n'utiliser qu'une seule dépendance (externe) : ArrayFire qui peut amener l'optimisation via GPU (résumer ça en 3 points majeurs) 
	Tel que décrit dans le titre du stage, les notions abordées seront reliées, dans un premier temps aux performances de MIRTK, pour cela, M. Maxime NOEL et moi-même sommes intervenus sur différents niveaux d'abstraction du logiciel. Mon collègue s'est d'avantage concentré sur l'enchaînement des exécutions, et l'interface MIRTK/utilisateur (cf stage intitulé" \textbf{?????????????????????????????????????????}"), tandis que je suis intervenu dans les couches logicielles les plus basses, et les plus directement reliées aux composants hardware. \\
	
	La majeure partie du stage sera donc axée sur le back-end mathématique de MIRTK, c'est-à-dire les fonctions appliquant des opérations matricielles sur les images d'entrée par exemple. L'un des problèmes majeurs de MIRTK est sa forte dépendance de plusieurs bibliothèque qui, chacune, ne sont pas utilisées au maximum de leur potentiel, il s'agit de EIGEN, BOOST et TBB, dont les rôles sont définis ci-dessous:\\
		\\{$\bullet$} \textit{EIGEN:} cette bibliothèque fournit les fonctions essentielles en termes de manipulation de matrice. \newline
		\\{$\bullet$} \textit{BOOST:} écrite en C++, cette bibliothèque fournit des outils d'algèbre linéaire, de traitement d'image ou encore de génération de nombres pseudo-aléatoire... \newline
		\begin{wrapfigure}[13]{r}{9cm}
			\includegraphics[width=10cm]{Reports/figures/gfor.eps}	
			\caption{Fonctionnement d'une boucle en parallèle}
			\label{Fonctionnement d'une boucle en parallèle}
		\end{wrapfigure}\\
		{$\bullet$} \textit{Threading Building Blocks (TBB)}: 
		\\

	TBB permet l'implémentation de boucles a exécuter en parallèle. L'exécution parallèle (ou \textit{multi-threading}) est une méthode d'optimisation des performances d'un logiciel. Elle consiste a dédier plusieurs "threads" à son exécution, et transforme donc un processus itératif tel qu'une boucle FOR en une répartition de toutes les itérations, mais exécutées en simultanées. Le temps d'exécution est donc au final considérablement réduit. On peut voir le fonctionnement d'une parallélisation sur, par exemple, une boucle "for" ci-contre:\vspace{1,5cm}\\
	
	Ainsi, l'inconsistance de MIRTK autour de ces 3 bibliothèques implique des performances parfois médiocres, et surtout une parallélisation réalisée de manière assez floue, dont l'efficacité est encore à prouver.  
	\\ C'est pour cette raison, que l'apport d'une bibliothèque coordonnant des fonctions issues d'au moins 2 des 3 dépendances précédentes sera un véritable avantage si les performances du logiciel sont améliorées, ou même si elles demeurent inchangées. 
		

	 \newpage

	\section{Cahier des charges}
%	Lister les attentes et les contraintes du projet.
	ArrayFire pourrait être la bibliothèque la plus adaptée pour ce genre de situation puisqu'elle est similaire à l'actuelle bibliothèque EIGEN, mais en permettant l'optimisation du logiciel. Pour palier cette faiblesse d'EIGEN, TBB était nécessaire, mais pas avec ArrayFire. De plus, ArrayFire ajoute la possibilité de gérer le changement de back-end afin de travailler sur un GPU (carte graphique), ou sur un CPU (processeur).\\
	\\
	Avec cette bibliothèque, il va être possible de réaliser les points suivants:\\ 
		\\{$\bullet$} Revoir les fonctions les plus coûteuses en ressources et dont les performances sont les plus médiocre, en les recodant avec ArrayFire.\\
		\\{$\bullet$} Supprimer intégralement toute dépendance à TBB puisque la parallélisation du code se fera exclusivement avec ArrayFire.\\
		\\{$\bullet$} La programmation sera réalisée de manière transparente, c'est-à-dire que MIRTK doit réaliser les mêmes fonctions et garder le même front-end même si le code plus en profondeur est modifié. En revanche, il sera possible d'ajouter des options d'exécution, notamment en ce qui concerne la gestion des back-end.\\
		\\{$\bullet$} Plusieurs benchmarks devront affirmer la pertinence du nouveau code de MIRTK en comparant les test de performances avant et après l'intégration d'ArrayFire.\\
%(Le délivrable sera composé IDEALEMENT de 2 backends, l'un AF et l'autre EIGEN. En fonction des applications, un switch automatique entre chaque structure sera appelé en dur grâce à des commandes pré-proc.) => étape bonus
		\\{$\bullet$} A l'issue du stage, s'il reste suffisamment de temps pour s'y intéresser, il serait idéal d'implémenter une fonctionnalité de changement automatique de back-end en fonction des performances de EIGEN et ArrayFire sur une fonction en particulier. En se basant purement sur un critère de performances, on pourrait par exemple avoir une génération de matrice initiée par EIGEN puis une rotation de matrice exécutée par ArrayFire. Les commandes de changement automatique de back-end seront idéalement codées dans le pré-processeur du code de MIRTK. Il restera tout de même une possibilité d'empêcher cette bascule automatisée (qui sera au final définie par défaut) par commande manuelle.
	\\
	\\
	\textit{Je tiens à préciser que les différents points du cahier des charges listé ci-dessus sont idéaux. Ne sachant pas à quoi s'attendre lors de l'étude de MIRTK, il se peut que ces différents points se voient modifiés, en fonction de la difficulté, du temps requis ou encore de la possibilité de leur réalisation.} 
	\section{Stratégie employée}
	\subsection{Objectifs} 
%	Détailler les objectifs a atteindre idéalement.
%	- Ajouter ArrayFire à MIRTK, en remplaçant les fonctions d'EIGEN les moins adaptées par les fonctions d'AF. \newline
%	- Faire un profiling des fonctions concernées par TBB, et interpréter les résultats afin d'élaborer une stratégie pour implanter la programmation // d'AF.\newline
%	- Supprimer les TBB inutiles ou peu efficaces, et remplacer les autres par l'équivalent d'AF (gfor).\newline
	\noindent Dans un premier temps, il faudrait analyser le code de MIRTK sur deux plans:\\~\par 
	\t - Les fonctions utilisées par Eigen et qui seraient davantage adaptées avec ArrayFire \\~\par
	\t - Les outils de parallélisation et l'utilisation de la bibliothèque TBB \\\\
	La première étape se fera simplement en comparant l'utilisation directe de Eigen, ainsi que les interdépendances des fichiers MIRTK avec ceux de la bibliothèque. Cependant, la deuxième demandera une analyse plus approfondie: en plus d'une analyse de code tel que précédemment avec EIGEN, il faudra réaliser un "test de performance" sur certaines fonctions. Ce test est appelé un profilage (ou \textit{profiling} en anglais) et peut analyser différents critères. Ainsi pourrons-nous cibler les fonctions les plus urgentes à modifier, qui sont mal rédigées ou qui demande relativement trop de ressources.
	A la suite de ce profilage sera donc élaboré un "plan d'attaque" pour savoir par quelle partie du projet commencer.
	\t - A terme, après avoir retiré au maximum les dépendances de MIRTK avec TBB, on pourra commencer des tests de benchmarking afin de vérifier l'amélioration des performances.
	\subsection{Diagramme de GANTT}
	 => gantt chart prévisionnel (à mettre en français)
	\begin{figure}[h!]
		\begin{center}
			\includegraphics[width=18cm]{Reports/figures/estimated_gantt.png}
		\end{center}	
		\caption{Diagramme de GANTT prévisionnel}
		\label{Diagramme de GANTT prévisionnel}
	\end{figure}
\chapter{Réalisation}
	\section{Profilage}
%	Définir le profilage et expliquer la nécessité d'une telle étape dans ce contexte\newline
	Lors du début de mon stage, il a fallu que je me familiarise avec les dépendances de MIRTK, mais aussi a son fonctionnement interne. C'est lors de cette étude préliminaire que mon tuteur et moi avons étudié, en plus de la bibliothèque EIGEN (destinée aux fonctionnalité mathématiques), la bibliothèque TBB, qui a pour but de mettre en place une parallélisation d'un logiciel. Constatant qu'ArrayFire était constitué de fonctions mathématiques déjà optimisées sur ce plan, il a été convenu de faire un profilage de MIRTK avant d'y intégrer ArrayFire afin de prioriser les points les plus coûteux en ressources de MIRTK. \\
%	Les tests ont été effectués sur une machine dont les caractéristiques sont les suivantes : \newline
%	{$\bullet$} \textit{Nombre de coeurs:} 8, 2 threads chacun\newline
%	{$\bullet$} \textit{Cadence:} 1.6 GHz \newline
%	{$\bullet$} \textit{Nombre de caches:} 4 \newline
%	{$\bullet$} \textit{Taille des caches:}32k, 32k, 256K, 8192K \newline
	%ajouter le maximum de détails (RAM, nom du proc ...)\newline
	Pour une quantité réduite de tests, et afin de cibler les modèles d'utilisation de TBB à remplacer, on a pris l'une des fonctions les plus sollicitées dans MIRTK, il s'agit d'une fonction nommée \textit{transform-image}, et qui dispose de 5 options, définissant un type d'interpolation mathématique : Linéaire (par défaut), méthode voisin le plus proche (NN), gaussienne, sinus cardinal et B-Spline. \\
	On notera, de plus, que tous ces tests seront exécutés sur la même machine afin de garder des performances exactement semblables à chaque exécution.
	
	\subsection{Choix du profileur}~\par
	Afin de discerner au mieux les performances de MIRTK, le choix du profileur (l'outil faisant le profilage) était important. Le principal poste utilisée pour le profilage travaille sur un processeur INTEL, ce qui nous a convaincu de ne pas utiliser le profileur CodeXl puisque nous avons compris après installation qu'il ne fonctionnait qu'avec des processeurs AMD. On a ensuite basculé sur VTune, développé par les collaborateurs directs d'AMD, mais nous ne l'avons pas retenu non plus de part sa complexité d'installation sur l'ordinateur souhaité.
	
	Nous avons donc finalement choisi d'utiliser l'outil Callgrind de la suite VALGRIND (qui est open-source), capable d'analyser à la fois la quantité d'instructions envoyées au run-time, et aussi les fuites de cache.
	Ci-dessous est affichée l'interface utilisateur de Kcachegrind, qui est un outil permettant de visualiser de manière claire les résultats de Callgrind:
	\begin{figure}[h!]
		\begin{center}
			\includegraphics[width=13cm]{Reports/figures/UIkcachegrind.png}
		\end{center}	
		\caption{Interface de KCacheGrind pour le profilage}
		\label{Interface de KCacheGrind pour le profilage}
	\end{figure}~\par
	{$\bullet$} \textit{Cadre vert: } Dans cette partie est distinguée tous les threads qui ont exécuté une partie du code lié à l'exécutable étudié. Tous les threads ayant été utilisés dans ce cas, on peut constater que la machine fonctionne donc avec 4 coeurs. \newline
	{$\bullet$} \textit{Cadre bleu: } Ici est détaillé toutes les fonctions les plus coûteuses du thread sélectionné. \newline
	{$\bullet$} \textit{Cadre rouge: } Grâce à ce diagramme, on peut visualiser la pile d'appel des fonctions avant et après la fonction sélectionné dans le cadre bleu. Les onglets en bas de page sont d'autres représentations plus textuelles (et plus détaillées) de ce que montre le diagramme. \newline
	
	

%	=> on identifie les fonctions sur lesquelles agir en premier
%	On utilise Valgrind, qui, avec callgrind analyse la manière dont les caches sont utilisés.
%	Expliquer le choix de valgrind, parmi les autres profileurs
% => projet open-source multi-plateforme et disponible dans les packages linux, autres alternatives étudiées (VTUNE intel, installation compliquée, et codeXL, qui nécessite des proc AMD).\\
	
	

	
	\subsection{Analyse du nombre d'instructions}
	
	\begin{wrapfigure}{r}{7.2cm}
		\includegraphics[height=9cm]{Reports/figures/smooth_image_costs.eps}
		\caption{Coût de la fonction de flou gaussien}
		\label{Coût de la fonction de flou gaussien}
	\end{wrapfigure}
	~\par~\par
	Dans un premier temps, on s'intéresse au critère le plus pertinent concernant les performances du logiciel. Le nombre d'instructions correspond à la quantité de commandes atomiques (au niveau binaire) exécutées par le CPU et pour chaque thread.
	Ainsi, on peut étudier l'efficacité de TBB en comparant le nombre d'instructions utilisées lorsque TBB est activé ou non. C'est ce qui est présenté sur l'image présentée ci-contre, en se focalisant sur une fonction de flou gaussien (nommée \textit{smooth-image}).\\
	Sur l'axe des ordonnées, on a le coût total en instruction de la fonction, appelée sur une machine précise, avec une entrée précise (ici une image 3D). Les résultats dépendent de ces deux critères.Cependant, le ratio entre les coûts de la fonction parallélisée et celle qui ne l'est pas reste sensiblement le même. Au bas de l'image, on peut voir qu'ici, la fonction à un taux d'amélioration de x1.59. L'ordinateur ayant exécuté cette fonction ayant 8 coeurs, on peut dire que ce résultat reflète une mauvaise parallélisation dans ce cas, car un logiciel bien optimisé aurait un taux d'amélioration proche de x8 (équivalent au nombre de coeurs utilisés).\\
	De même, ci-dessous, l'image décrit les performances de la fonction \textit{transform-image}. En revanche, ici, cette fonction possède une option qui permet de choisir son type d'interpolation mathématique. On a donc fait un test de coût d'instructions pour chaque interpolation et on a relevé ici le taux de performance associé:
	\begin{figure}[h!]
		\begin{center}
			\includegraphics[width=9cm]{Reports/figures/performances_tbb_transform_image.eps}
		\end{center}	
		\caption{Améliorations apportées par TBB pour transform-image}
		\label{Améliorations apportées par TBB pour transform-image}
	\end{figure}~\par
	L'interpolation gaussienne est donc parfaitement parallélisée, ce qui n'est pas le cas des autres interpolations de \textit{transform-image}.
	\subsection{Analyse des fuites de cache}
	Un deuxième critère intéressant à regarder, au travers du profilage, est la quantité de fuites de caches à l'exécution de la fonction étudiée. Bien que la parallélisation ne soit pas toujours optimale, elle peut néanmoins être parfois délaissée au profit d'une gestion de fuites de caches plus poussée.
	\paragraph{Qu'est-ce qu'une fuite de cache?}
	\textit{?????}\\
	Ci-dessous est détaillé l'histogramme de la quantité des fuites de caches pour \textit{transform-image}, dans chaque mode d'interpolation:
		\begin{figure}[h!]
			\begin{center}
				\includegraphics[width=15cm]{Reports/figures/cache_misses_transform_image.eps}
			\end{center}	
			\caption{Fuites de cache pour la fonction transform-image}
			\label{Fuites de cache pour la fonction transform-image}
		\end{figure}~\par
	Les valeurs données ci-dessus (en pourcentage) sont assez mal réparties, mais le faible "cache miss rate" (taux de fuites de caches) est très faible. Le seul taux non négligeable est celui des mauvaises prédictions de branche, qui peut être considéré comme une fuite de cache, mais un taux inférieur à 20 \% reste négligeable. 
	
	~\par
	MIRTK est donc bien conçu au niveau de la gestion de la mémoire cache, alors que le système de parallélisation est largement améliorable.
	
	\section{Intégration d'ArrayFire dans MIRTK}
	\subsection{Implémentation du module mathématique}
%	Programmation transparente entre Eigen et ArrayFire.
%	Lister les fonctions principales à substituer.
L'une des première fonctions qui nous a attiré était un filtre, qui avait une implémentation assez simple (un simple produit de convolution de deux matrices). On a donc choisi de s'y intéresser avec ArrayFire.
Smooth image :
	\begin{figure}[h!]
		\begin{center}
			\includegraphics[width=12cm]{Reports/figures/gaussianblurring.png}
		\end{center}	
		\caption{Algorithme de flou gaussien incluant Arrayfire - Implémentation naïve}
		\label{Algorithme de flou gaussien incluant Arrayfire - Implémentation naïve}
	\end{figure}
	\begin{figure}[h!]
		\begin{center}
			\includegraphics[width=12cm]{Reports/figures/mygaussianblurring.png}
		\end{center}	
		\caption{Algorithme de flou gaussien incluant Arrayfire - Implémentation optimisée}
		\label{Algorithme de flou gaussien incluant Arrayfire - Implémentation optimisée}
	\end{figure}~\par
	\subsection{Gestion de la programmation parallèle}
%	Optimisation des threads et suppression de TBB au profit de ArrayFire.

	

	
%	\newline
%	Le contenus des sous-parties, ainsi que d'éventuelles d'autres sous-parties dépendront du résultat du profilage.
	\subsection{Switch automatique de back-end}
%	Commandes prépocesseur pour indiquer au logiciel quel est le back-end à utiliser (ArrayFire ou Eigen) en fonction de l'opération souhaitée.

	\section{Benchmarking}
	(partie dépendante du déroulement du projet)\newline
	- Analyse des performances obtenues \newline
	- Comparaison avec le profilage initial ? \newline
	- Points où il y a eu des concessions (exemple: alourdir le code pour parvenir à un résultat précis)
	
\chapter{Améliorations et perspectives}
	\section{Au niveau technique...}
	\section{...mais pas seulement!}

\chapter*{Conclusion} % dans cet ordre
\addcontentsline{toc}{chapter}{Conclusion}
\chapter*{Sources}
\addcontentsline{toc}{chapter}{Sources}
\noindent
\url{https://biomedia.doc.ic.ac.uk/}  : image page de garde, partie du texte 1.1.2 \\
\url{http://www.imperial.ac.uk} : partie du texte 1.1.1 (Department of computing) et schéma stratégie du département\\
\url{https://fr.wikipedia.org/wiki/Imperial_College_London} : partie du texte 1.1.1 (Imperial College London)\\
\url{http://ric.uthscsa.edu/mango/papaya/index.html} : outil de visualisation d'images en format NIFTI
\renewcommand{\listfigurename}{Table des illustations}
\listoffigures
\addcontentsline{toc}{chapter}{Table des illustrations}
\chapter*{Glossaire}
\addcontentsline{toc}{chapter}{Glossaire}
\noindent
\textbf{Back-end:}\\ 
\textbf{Front-end:}\\
\textbf{MIRTK:}\\
\textbf{Profilage:} Différence avec le benchmarking ?\\
\textbf{Run-time:}\\
\textbf{Fuite de cache:}\\
\textbf{Benchmarking:} Différence avec le profiling ?\\
\textbf{Thread:}\\
\textbf{Prédiction de branche:}\\
\textbf{Fuite de cache:}\\


\chapter*{Annexes}
\addcontentsline{toc}{chapter}{Annexes}
\end{document}
